{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwaGIjmITufIW9xpr1tpCB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loader**\n",
        "\n",
        "A data loader in **PyTorch** is responsible for efficiently loading and batching data from a data set. It abstracts away the process of iterating over a data set, shuffling, and dividing it into batches for training. In NLP applications, the data loader is used to process and transform your text data, rather than just the data set.\n",
        "\n",
        "Data loaders have several key parameters, including the data set to load from, batch size (determining how many samples per batch), shuffle (whether to shuffle the data for each epoch), and more. Data loaders also provide an iterator interface, making it easy to iterate over batches of data during training.\n",
        "\n",
        "An iterator is an object that can be looped over. It contains elements that can be iterated through and typically includes two methods, `__iter__()` and `__next__()`. When there are no more elements to iterate over, it raises a **`StopIteration`** exception.\n",
        "\n",
        "Iterators are commonly used to traverse large data sets without loading all elements into memory simultaneously, making the process more memory-efficient. In PyTorch, not all data sets are iterators, but all data loaders are.\n",
        "\n",
        "In PyTorch, the data loader processes data in batches, loading and processing one batch at a time into memory efficiently. The batch size, which you specify when creating the data loader, determines how many samples are processed together in each batch. The data loader's purpose is to convert input data and labels into batches of tensors with the same shape for deep learning models to interpret.\n",
        "\n",
        "Finally, a data loader can be used for tasks such as tokenizing, sequencing, converting your samples to the same size, and transforming your data into tensors that your model can understand.\n"
      ],
      "metadata": {
        "id": "hMjzQ6QqYOLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Install Necessary Libraries\n",
        "\n",
        "print(\"--- Installing Libraries ---\")\n",
        "\n",
        "# Uninstall conflicting packages\n",
        "!pip uninstall -y torch torchtext torchdata numpy\n",
        "\n",
        "# Reinstall compatible versions\n",
        "!pip install torch==2.2.2 torchtext==0.17.2 torchdata==0.7.1 numpy==1.24.4\n",
        "\n",
        "print(\"\\n--- Installation and Downloads Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q5-S_qurZ-68",
        "outputId": "631ec51a-26c9-4ab8-f4bc-80d98b1f6260"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Installing Libraries ---\n",
            "Found existing installation: torch 2.2.2\n",
            "Uninstalling torch-2.2.2:\n",
            "  Successfully uninstalled torch-2.2.2\n",
            "Found existing installation: torchtext 0.17.2\n",
            "Uninstalling torchtext-0.17.2:\n",
            "  Successfully uninstalled torchtext-0.17.2\n",
            "Found existing installation: torchdata 0.11.0\n",
            "Uninstalling torchdata-0.11.0:\n",
            "  Successfully uninstalled torchdata-0.11.0\n",
            "Found existing installation: numpy 1.24.4\n",
            "Uninstalling numpy-1.24.4:\n",
            "  Successfully uninstalled numpy-1.24.4\n",
            "Collecting torch==2.2.2\n",
            "  Using cached torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchtext==0.17.2\n",
            "  Using cached torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting torchdata==0.7.1\n",
            "  Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting numpy==1.24.4\n",
            "  Using cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.2.2) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.17.2) (2.32.3)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.1) (2.4.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.17.2) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.2.2) (1.3.0)\n",
            "Using cached torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "Using cached torchtext-0.17.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "Downloading torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy, torch, torchtext, torchdata\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "blosc2 3.4.0 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.1 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.4 torch-2.2.2 torchdata-0.7.1 torchtext-0.17.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "0145c5c6072e4f10b130d1646389b85d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Installation and Downloads Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Necessary Libraries\n",
        "\n",
        "print(\"--- Importing Libraries ---\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "import torchtext\n",
        "print(torch.__version__)\n",
        "print(torchtext.__version__)\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from torchdata.datapipes.iter import IterableWrapper, Mapper\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "print(\"\\nAll necessary libraries imported.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE25hwFyZ4PC",
        "outputId": "066b16c0-6f1a-4964-f13c-27442e92ea47"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Importing Libraries ---\n",
            "2.2.2+cu121\n",
            "0.17.2+cpu\n",
            "\n",
            "All necessary libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uY3XHvwhYIna"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"There's a lady who's sure all that glitters is gold\",\n",
        "    \"And she's buying a stairway to Heaven\",\n",
        "    \"When she gets there she knows, if the stores are all closed\",\n",
        "    \"With a word she can get what she came for\",\n",
        "    \"Ooh, ooh, and she's buying a stairway to Heaven\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define a custom data set\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, sentences, tokenizer, vocab):\n",
        "        self.sentences = sentences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.tokenizer(self.sentences[idx])\n",
        "        # Convert tokens to tensor indices using vocab\n",
        "        tensor_indices = torch.tensor([self.vocab[token] for token in tokens], dtype=torch.long)\n",
        "        return torch.tensor(tensor_indices)\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, sentences), specials=[\"<PAD>\", \"<UNK>\"])\n",
        "vocab.set_default_index(vocab[\"<UNK>\"])  # Handle unknown tokens\n",
        "\n",
        "# Create an instance of your custom data set\n",
        "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
        "\n",
        "print(\"Custom Dataset Length:\", len(custom_dataset))\n",
        "print(\"Sample Items:\")\n",
        "for i in range(len(custom_dataset)):\n",
        "    sample_item = custom_dataset[i]\n",
        "    print(f\"Item {i + 1}: {sample_item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftpMmBrCZh9k",
        "outputId": "5d6467af-0f98-406d-d825-981864fae058"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Dataset Length: 5\n",
            "Sample Items:\n",
            "Item 1: tensor([13,  3,  5,  4, 27, 34,  3,  5, 29,  7, 30, 22, 25, 23])\n",
            "Item 2: tensor([ 8,  2,  3,  5,  9,  4, 12, 14, 10])\n",
            "Item 3: tensor([33,  2, 21, 13,  2, 26,  6, 24, 31, 28, 15,  7, 18])\n",
            "Item 4: tensor([35,  4, 36,  2, 17, 20, 32,  2, 16, 19])\n",
            "Item 5: tensor([11,  6, 11,  6,  8,  2,  3,  5,  9,  4, 12, 14, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-3961106626.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(tensor_indices)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define Collate Function with Sorting and Padding\n",
        "\n",
        "def collate_batch(batch):\n",
        "    # Sort by length (descending)\n",
        "    batch.sort(key=lambda x: len(x), reverse=True)\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_batch = pad_sequence(batch, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
        "\n",
        "    # Create attention masks (optional, good for Transformer models)\n",
        "    lengths = torch.tensor([len(seq) for seq in batch])\n",
        "\n",
        "    return padded_batch, lengths"
      ],
      "metadata": {
        "id": "HmHOU5UHi61O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create DataLoader with Batch Size 3\n",
        "\n",
        "# Instantiate dataset\n",
        "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
        "\n",
        "# Create DataLoader\n",
        "data_loader = DataLoader(\n",
        "    custom_dataset,\n",
        "    batch_size=3,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch\n",
        ")"
      ],
      "metadata": {
        "id": "dd7fbrQajDog"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Iterate and Print Batches\n",
        "\n",
        "print(\"Batches:\")\n",
        "for i, (batch, lengths) in enumerate(data_loader):\n",
        "    print(f\"\\nBatch {i + 1}:\")\n",
        "    print(\"Padded Sequences:\\n\", batch)\n",
        "    print(\"Sequence Lengths:\\n\", lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNKu8XTLjMQI",
        "outputId": "f0ac40dc-0823-4215-fb3a-84049e77fbb5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches:\n",
            "\n",
            "Batch 1:\n",
            "Padded Sequences:\n",
            " tensor([[13,  3,  5,  4, 27, 34,  3,  5, 29,  7, 30, 22, 25, 23],\n",
            "        [33,  2, 21, 13,  2, 26,  6, 24, 31, 28, 15,  7, 18,  0],\n",
            "        [ 8,  2,  3,  5,  9,  4, 12, 14, 10,  0,  0,  0,  0,  0]])\n",
            "Sequence Lengths:\n",
            " tensor([14, 13,  9])\n",
            "\n",
            "Batch 2:\n",
            "Padded Sequences:\n",
            " tensor([[11,  6, 11,  6,  8,  2,  3,  5,  9,  4, 12, 14, 10],\n",
            "        [35,  4, 36,  2, 17, 20, 32,  2, 16, 19,  0,  0,  0]])\n",
            "Sequence Lengths:\n",
            " tensor([13, 10])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-6-3961106626.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(tensor_indices)\n"
          ]
        }
      ]
    }
  ]
}