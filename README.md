# GenAI

Comprehensive Generative AI and Large Language Models - from fundamentals to production applications.

## Overview

This repository documents my exploration of Generative AI, covering everything from foundational NLP concepts to modern LLM applications. Each notebook represents hands-on implementation of key GenAI techniques.

## Notebooks by Category

### üéØ Production Applications
- **[AI Cover Letter Generator](CoverLeterGenerator_Interface.ipynb)** - Complete LangGraph application with Gradio UI
- **[Simple ChatBot](SimpleChatBot.ipynb)** - Conversational AI implementation
- **[LLMs with RAG and HuggingFace](LLMs_RAGandHuggingFace.ipynb)** - Retrieval-augmented generation system

### üèóÔ∏è Transformer Architectures
- **[Self-Attention & Positional Encoding](SelfAttention_PositionalEncoding.ipynb)** - Core transformer mechanisms
- **[Transformer for Translation](Transformer_for_Translation.ipynb)** - Sequence-to-sequence models
- **[Transformers for Classification](Transformers_for_Classification.ipynb)** - Text classification tasks
- **[Decoder-Only Models (GPT)](Decoder_Causal_LM_GPT.ipynb)** - Causal language modeling

### üîß Fine-Tuning & Training
- **[Fine-Tuning with SFT](Fine_Tuning_SFTTransformers.ipynb)** - Supervised fine-tuning
- **[Pre-training BERT](PreTrainingBERT.ipynb)** - Masked language modeling
- **[Pre-training LLMs](PretrainingLLMs_HuggingFace.ipynb)** - Training from scratch
- **[Reward Modeling](Reward_Modeling.ipynb)** - RLHF foundations
- **[Data Prep for BERT](DataPrep_for_BERT.ipynb)** - Dataset preparation

### üìö NLP Fundamentals
- **[Tokenization](Tokenization.ipynb)** - BPE, WordPiece, SentencePiece
- **[Word2Vec](Word2Vec.ipynb)** - Word embeddings
- **[N-gram Language Models](Language_Modelling_With_N_Gram_Analysis.ipynb)** - Statistical language modeling
- **[RNN Translation](S_to_S_RNN_Translation.ipynb)** - Sequence-to-sequence with RNNs

### üõ†Ô∏è Tools & Infrastructure
- **[HuggingFace Models](ModelsWithHuggingFace.ipynb)** - Working with pre-trained models
- **[LangChain Document Loader](LangChain_Document_Loader.ipynb)** - Document processing pipelines
- **[NLP Data Loader](NLP_DataLoader.ipynb)** - Dataset handling

## Technologies

**Frameworks & Libraries**
- Transformers (HuggingFace)
- LangChain
- LangGraph
- PyTorch
- TensorFlow

**Models**
- BERT, GPT, T5
- Llama, Mistral
- Custom trained models

**Applications**
- RAG systems
- Fine-tuning & PEFT
- Prompt engineering
- Multi-agent systems

## Learning Path

**Beginner Track**
1. Start with [Tokenization](Tokenization.ipynb)
2. Understand [Word2Vec](Word2Vec.ipynb)
3. Learn [N-gram models](Language_Modelling_With_N_Gram_Analysis.ipynb)

**Intermediate Track**
4. Deep dive into [Transformers](SelfAttention_PositionalEncoding.ipynb)
5. Explore [BERT](PreTrainingBERT.ipynb) and [GPT](Decoder_Causal_LM_GPT.ipynb)
6. Build [Classification models](Transformers_for_Classification.ipynb)

**Advanced Track**
7. Implement [RAG systems](LLMs_RAGandHuggingFace.ipynb)
8. Practice [Fine-tuning](Fine_Tuning_SFTTransformers.ipynb)
9. Build [Production apps](CoverLeterGenerator_Interface.ipynb)

## Key Concepts Covered

‚úÖ Transformer architecture and self-attention  
‚úÖ Pre-training vs fine-tuning strategies  
‚úÖ Retrieval-augmented generation (RAG)  
‚úÖ Prompt engineering and optimization  
‚úÖ RLHF and reward modeling  
‚úÖ Production deployment patterns  
‚úÖ Multi-agent LLM systems  

## Related Work

**For broader AI/ML context:**
- [AI-Agents](../AI-Agents) - Multi-agent systems with crewAI and LangGraph
- [Deep-Learning-Fundamentals](../Deep-Learning-Fundamentals) - Neural network foundations
- [Python-AI-Applications](../Python-AI-Applications) - Computer vision and audio processing
- [ML-Fundamentals-Portfolio](../ML-Fundamentals-Portfolio) - Classical ML algorithms

---

## Context

This repository represents my deep dive into Generative AI and LLMs - the technologies reshaping AI in 2025. Each notebook combines theoretical understanding with practical implementation, suitable for both learning and reference.

**Built with 22+ years of ML experience, now focused on cutting-edge GenAI applications.**

---

*All notebooks created and tested in Google Colab - ready to run.*
