{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5n1Cg7I7VilvqWH786bUQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building a Language Model Using Histogram N-Gram Analysis"
      ],
      "metadata": {
        "id": "hszUueEDFfXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing required libraries\n",
        "Install these libraries using the code cell below.\n",
        "\n",
        "After installing the libraries below please RESTART THE KERNEL and run all cells."
      ],
      "metadata": {
        "id": "zF5HV9izFCNG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmLqkqUPEtML"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "!pip install torch==2.6.0\n",
        "!pip install torchtext==0.17.2\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Importing required libraries\n",
        "\n",
        "%%capture\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "import time\n",
        "from collections import OrderedDict\n",
        "\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import string\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# You can also use this section to suppress warnings generated by your code:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn\n",
        "%capture"
      ],
      "metadata": {
        "id": "qKX53tqVGsRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define a support function\n",
        "\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = re.sub(r\"[^\\w\\s]\", '', s)\n",
        "    # Replace all runs of whitespaces with no space\n",
        "    s = re.sub(r\"\\s+\", '', s)\n",
        "    # replace digits with no space\n",
        "    s = re.sub(r\"\\d\", '', s)\n",
        "\n",
        "    return s"
      ],
      "metadata": {
        "id": "1N59dKELHRfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language Modeling\n",
        "\n",
        "Language modeling is a foundational concept within the field of natural language processing (NLP) and artificial intelligence. It involves the prediction of the likelihood of a sequence of words within a given language. This method is statistical in nature and seeks to capture the patterns, structures, and relationships that exist between words in a given text corpus.\n",
        "\n",
        "At its essence, a language model strives to comprehend the probabilities associated with sequences of words. This comprehension can be leveraged for a multitude of NLP tasks, including but not limited to text generation, machine translation, speech recognition, sentiment analysis, and more.\n",
        "\n",
        "Let's consider the following song lyrics to determine if you can generate similar output using a given word."
      ],
      "metadata": {
        "id": "Mdov4IS_E9oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "song = \"\"\" It's been a long time since I rock and rolled\n",
        "It's been a long time since I did the stroll\n",
        "Ooh, let me get it back, let me get it back\n",
        "Let me get it back, baby, where I come from\n",
        "It's been a long time, been a long time\n",
        "Been a long lonely, lonely, lonely, lonely, lonely time\n",
        "Yes, it has\n",
        "It's been a long time since the Book of Love\n",
        "I can't count the tears of a life with no love\n",
        "Carry me back, carry me back\n",
        "Carry me back, baby, where I come from\n",
        "Whoa, whoa, oh\n",
        "It's been a long time, been a long time\n",
        "Been a long lonely, lonely, lonely, lonely, lonely time\n",
        "Oh, seems so long since we walked in the moonlight\n",
        "Making vows that just can't work right\n",
        "Oh yeah, open your arms, opens your arms\n",
        "Open your arms, baby, let my love come running in\n",
        "Yeah!\n",
        "It's been a long time, been a long time\n",
        "Been a long lonely, lonely, lonely, lonely, lonely time\n",
        "Yeah, yeah\n",
        "Yeah, yeah\n",
        "Ooh yeah, ooh yeah\n",
        "Ooh yeah, ooh yeah\n",
        "It's been a long time, been a long time\n",
        "Been a long lonely, lonely, lonely, lonely, lonely time\"\"\""
      ],
      "metadata": {
        "id": "6SFSV9joHpGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Natural Language Toolkit (NLTK)\n",
        "\n",
        "NLTK is indeed a widely-used open-source library in Python that is specifically designed for various natural language processing (NLP) tasks. It provides a comprehensive set of tools, resources, and algorithms that aid in the analysis and manipulation of human language data."
      ],
      "metadata": {
        "id": "mMr955AMIHDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization\n",
        "\n",
        "Tokenization is the process of breaking down a body of text into discrete units known as tokens. For this project, we will focus on Word Tokenization, this technique treats each word in the text as an independent entity. Words, typically separated by spaces or punctuation marks, serve as the tokens in this approach. It's important to note that Word Tokenization exhibits versatile characteristics, including capitalization, symbols, and punctuation marks.\n",
        "\n",
        "We will utilize the```word_tokenize```function. During this process, we will remove punctuation, symbols, and capital letters."
      ],
      "metadata": {
        "id": "ffnxjoieIXvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "def preprocess(words):\n",
        "    tokens=word_tokenize(words)\n",
        "    tokens=[preprocess_string(w)   for w in tokens]\n",
        "    return [w.lower()  for w in tokens if len(w)!=0 or not(w in string.punctuation) ]\n",
        "\n",
        "tokens=preprocess(song)"
      ],
      "metadata": {
        "id": "rAOMPkuFI43F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[0:11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPnEDl4DJUuy",
        "outputId": "89b96d84-8c60-4ab0-884b-efaf2c09da23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it', 's', 'been', 'a', 'long', 'time', 'since', 'i', 'rock', 'and', 'rolled']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create a frequency distribution of words\n",
        "fdist = nltk.FreqDist(tokens)\n",
        "fdist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeWCUNzsJkux",
        "outputId": "f7bad360-704a-47b0-d7c7-ca0f6ef4ea1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'lonely': 20, 'a': 16, 'long': 16, 'been': 15, 'time': 15, 'it': 11, 'yeah': 10, 's': 7, 'me': 6, 'back': 6, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plot the words with the top ten frequencies.\n",
        "\n",
        "plt.bar(list(fdist.keys())[0:11],list(fdist.values())[0:11])\n",
        "plt.xlabel(\"Words\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "RvZRdIh8JsaY",
        "outputId": "109e0e11-20de-4af2-ad05-d04aa123bcc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unigram model\n",
        "An unigram model is a simple type of language model that considers each word in a sequence independently, without taking into account the previous words. In other words, it models the probability of each word occurring in the text, regardless of what came before it. Unigram models can be seen as a special case of n-gram models, where n is 1."
      ],
      "metadata": {
        "id": "dvmO3PbsKRTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#total count of each word\n",
        "\n",
        "C=sum(fdist.values())\n",
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9bFNyaMJuWr",
        "outputId": "fdc8553d-2422-46b8-cfac-4534a5aac553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "211"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist['rock']/C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXblEKmcKdv1",
        "outputId": "955c1288-8874-4779-9364-cf5cf79d6c44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004739336492890996"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary=set(tokens)\n",
        "vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9gh2FEzKkpJ",
        "outputId": "c3f608bd-c285-4c53-d11d-0e4d2e5f4b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'and',\n",
              " 'arms',\n",
              " 'baby',\n",
              " 'back',\n",
              " 'been',\n",
              " 'book',\n",
              " 'ca',\n",
              " 'carry',\n",
              " 'come',\n",
              " 'count',\n",
              " 'did',\n",
              " 'from',\n",
              " 'get',\n",
              " 'has',\n",
              " 'i',\n",
              " 'in',\n",
              " 'it',\n",
              " 'just',\n",
              " 'let',\n",
              " 'life',\n",
              " 'lonely',\n",
              " 'long',\n",
              " 'love',\n",
              " 'making',\n",
              " 'me',\n",
              " 'moonlight',\n",
              " 'my',\n",
              " 'no',\n",
              " 'nt',\n",
              " 'of',\n",
              " 'oh',\n",
              " 'ooh',\n",
              " 'open',\n",
              " 'opens',\n",
              " 'right',\n",
              " 'rock',\n",
              " 'rolled',\n",
              " 'running',\n",
              " 's',\n",
              " 'seems',\n",
              " 'since',\n",
              " 'so',\n",
              " 'stroll',\n",
              " 'tears',\n",
              " 'that',\n",
              " 'the',\n",
              " 'time',\n",
              " 'vows',\n",
              " 'walked',\n",
              " 'we',\n",
              " 'where',\n",
              " 'whoa',\n",
              " 'with',\n",
              " 'work',\n",
              " 'yeah',\n",
              " 'yes',\n",
              " 'your'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bigram Model\n",
        "\n",
        "Bigram models use conditional probability. The probability of a word depends only on the previous word, i.e., the conditional probability  is used to predict the likelihood of word following word  in a sequence. You can calculate the conditional probability for a bigram model using the following steps."
      ],
      "metadata": {
        "id": "dX-JoauGLK-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigrams = nltk.bigrams(tokens)\n",
        "bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjwS4sTWLJhw",
        "outputId": "53b943ee-9eb6-4e54-a389-d7330d598f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object bigrams at 0x79e506862880>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_bigrams=list(nltk.bigrams(tokens))"
      ],
      "metadata": {
        "id": "WjK6dsprLd71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_bigrams[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTX8XMHpLf5H",
        "outputId": "ea414747-830d-4100-905d-df93df82001f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('it', 's'),\n",
              " ('s', 'been'),\n",
              " ('been', 'a'),\n",
              " ('a', 'long'),\n",
              " ('long', 'time'),\n",
              " ('time', 'since'),\n",
              " ('since', 'i'),\n",
              " ('i', 'rock'),\n",
              " ('rock', 'and'),\n",
              " ('and', 'rolled')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Compute the frequency distribution of the bigram using the NLTK function bigrams.\n",
        "\n",
        "freq_bigrams  = nltk.FreqDist(nltk.bigrams(tokens))\n",
        "freq_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-nv90HNLmKd",
        "outputId": "0f6a6032-89e0-4112-8132-3c0f890a949a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('lonely', 'lonely'): 16, ('been', 'a'): 15, ('a', 'long'): 15, ('long', 'time'): 11, ('time', 'been'): 8, ('it', 's'): 7, ('s', 'been'): 7, ('long', 'lonely'): 4, ('lonely', 'time'): 4, ('yeah', 'ooh'): 4, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freq_bigrams[('rock', 'and')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVNsD8BqL5GK",
        "outputId": "80c1c5e8-d1bf-49bc-c17b-81483161cb28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title The first 10 values of the frequency distribution\n",
        "\n",
        "for my_bigram in  my_bigrams[0:10]:\n",
        "    print(my_bigram)\n",
        "    print(freq_bigrams[my_bigram])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB9RDfNGMCiy",
        "outputId": "7d7cbf4f-9340-40e8-d819-68c570df701b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('it', 's')\n",
            "7\n",
            "('s', 'been')\n",
            "7\n",
            "('been', 'a')\n",
            "15\n",
            "('a', 'long')\n",
            "15\n",
            "('long', 'time')\n",
            "11\n",
            "('time', 'since')\n",
            "3\n",
            "('since', 'i')\n",
            "2\n",
            "('i', 'rock')\n",
            "1\n",
            "('rock', 'and')\n",
            "1\n",
            "('and', 'rolled')\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate the conditional distribution\n",
        "# by normalizing the frequency distribution of unigrams.\n",
        "\n",
        "word=\"time\"\n",
        "vocab_probabilities={}\n",
        "for next_word in vocabulary:\n",
        "    vocab_probabilities[next_word]=freq_bigrams[(word,next_word)]/fdist[word]\n",
        "\n",
        "vocab_probabilities=sorted(vocab_probabilities.items(), key=lambda x:x[1],reverse=True)\n",
        "\n",
        "vocab_probabilities[0:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwx_q-0NMHBg",
        "outputId": "78958bc4-3add-49ca-9e64-dbe15b57f74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('been', 0.5333333333333333),\n",
              " ('since', 0.2),\n",
              " ('yes', 0.06666666666666667),\n",
              " ('yeah', 0.06666666666666667)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a function to calculate the conditional probability\n",
        "of $W_t$ given $W_{t-1}$, sort the results, and output them as a list."
      ],
      "metadata": {
        "id": "_30yz1HlNV40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def make_predictions(my_words, freq_grams, normlize=1, vocabulary=vocabulary):\n",
        "    \"\"\"\n",
        "    Generate predictions for the conditional probability of the next word given a sequence.\n",
        "\n",
        "    Args:\n",
        "        my_words (list): A list of words in the input sequence.\n",
        "        freq_grams (dict): A dictionary containing frequency of n-grams.\n",
        "        normlize (int): A normalization factor for calculating probabilities.\n",
        "        vocabulary (list): A list of words in the vocabulary.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predicted words along with their probabilities, sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    vocab_probabilities = {}  # Initialize a dictionary to store predicted word probabilities\n",
        "\n",
        "    context_size = len(list(freq_grams.keys())[0])  # Determine the context size from n-grams keys\n",
        "\n",
        "    # Preprocess input words and take only the relevant context words\n",
        "    my_tokens = preprocess(my_words)[0:context_size - 1]\n",
        "\n",
        "    # Calculate probabilities for each word in the vocabulary given the context\n",
        "    for next_word in vocabulary:\n",
        "        temp = my_tokens.copy()\n",
        "        temp.append(next_word)  # Add the next word to the context\n",
        "\n",
        "        # Calculate the conditional probability using the frequency information\n",
        "        if normlize!=0:\n",
        "            vocab_probabilities[next_word] = freq_grams[tuple(temp)] / normlize\n",
        "        else:\n",
        "            vocab_probabilities[next_word] = freq_grams[tuple(temp)]\n",
        "    # Sort the predicted words based on their probabilities in descending order\n",
        "    vocab_probabilities = sorted(vocab_probabilities.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return vocab_probabilities  # Return the sorted list of predicted words and their probabilities"
      ],
      "metadata": {
        "id": "rrHe-R_bNCrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_words=\"long\"\n",
        "\n",
        "vocab_probabilities=make_predictions(my_words,freq_bigrams,normlize=fdist['i'])\n",
        "\n",
        "vocab_probabilities[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFvkzKEcNez3",
        "outputId": "0acafba7-30bc-4b05-ad53-ddac404f80a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('time', 2.2),\n",
              " ('lonely', 0.8),\n",
              " ('since', 0.2),\n",
              " ('let', 0.0),\n",
              " ('stroll', 0.0),\n",
              " ('tears', 0.0),\n",
              " ('carry', 0.0),\n",
              " ('my', 0.0),\n",
              " ('making', 0.0),\n",
              " ('get', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_probabilities[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "asmkqywmOAbP",
        "outputId": "058f4523-bc65-4905-9661-a847eaaebc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'time'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Generate a sequence using the bigram model\n",
        "# by leveraging the preceding word (t-1) to predict the subsequent word.\n",
        "\n",
        "my_song=\"\"\n",
        "for w in tokens[0:100]:\n",
        "  my_word=make_predictions(w,freq_bigrams)[0][0]\n",
        "  my_song+=\" \"+my_word"
      ],
      "metadata": {
        "id": "Hc2EGTpLOJU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "my_song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "GsIHB_YBOWuP",
        "outputId": "e36ba6c6-b238-45c4-c067-e86c7b2c6fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' s been a long time been i come and rolled it s been a long time been i come the stroll ooh yeah me get it s let me get it s let me get it s let where i come from it s been a long time been a long time been a long time lonely lonely lonely lonely lonely been it s it s been a long time been i stroll of a carry come nt count the stroll of a long with no love carry me get let me get let me get let where i come'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_song=\"time\"\n",
        "\n",
        "for i in range(100):\n",
        "    my_word=make_predictions(my_word,freq_bigrams)[0][0]\n",
        "    my_song+=\" \"+my_word"
      ],
      "metadata": {
        "id": "ZbhUbAAHOqtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "MUtEYuhIOt6-",
        "outputId": "a8788297-cd66-4be5-c390-8e2f6dfd69c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'time a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been a long time been'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trigram Model\n",
        "\n",
        "Trigram models incorporate conditional probability as well. The probability of a word depends on the two preceding words. The conditional probability $P(W_t | W_{t-2}, W_{t-1})$ is utilized to predict the likelihood of word $W_t$ following the two previous words in a sequence. The context is $W_{t-2}, W_{t-1}$ and is of length 2."
      ],
      "metadata": {
        "id": "UGEzr1DSPQN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_trigrams  = nltk.FreqDist(nltk.trigrams(tokens))\n",
        "freq_trigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqXkVLOePcHu",
        "outputId": "1a2093d0-ccd2-465c-983f-d33a851b1d0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({('been', 'a', 'long'): 15, ('lonely', 'lonely', 'lonely'): 12, ('a', 'long', 'time'): 11, ('long', 'time', 'been'): 8, ('time', 'been', 'a'): 8, ('it', 's', 'been'): 7, ('s', 'been', 'a'): 7, ('a', 'long', 'lonely'): 4, ('long', 'lonely', 'lonely'): 4, ('lonely', 'lonely', 'time'): 4, ...})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_predictions(\"long time\",freq_trigrams,normlize=freq_bigrams[('long','time')] )[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHE1_4pePhD2",
        "outputId": "ec90ae8c-09cd-436a-8ff8-30ba177b4981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('been', 0.7272727272727273),\n",
              " ('since', 0.2727272727272727),\n",
              " ('let', 0.0),\n",
              " ('stroll', 0.0),\n",
              " ('tears', 0.0),\n",
              " ('carry', 0.0),\n",
              " ('my', 0.0),\n",
              " ('making', 0.0),\n",
              " ('get', 0.0),\n",
              " ('yes', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_song=\"\"\n",
        "\n",
        "w1=tokens[0]\n",
        "for w2 in tokens[0:100]:\n",
        "    gram=w1+' '+w2\n",
        "    my_word=make_predictions(gram,freq_trigrams )[0][0]\n",
        "    my_song+=\" \"+my_word\n",
        "    w1=w2"
      ],
      "metadata": {
        "id": "yzauUje6QPm4"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_song"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "49WCuwS1QQoo",
        "outputId": "41edf5f5-d8c3-42c0-edc1-1ec96b6a1b8d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' let been a long time been i rock and rolled it s been a long time been i rock the stroll ooh let me get it back let me get it back let me get it back let where i come from it s been a long time been a long time been a long time lonely lonely lonely lonely lonely yes it has it s been a long time been i book of love i ca nt count the tears of a life with no love carry me back carry me back carry me back carry where i come'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ]
}